{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Text Preprocessing</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, We'll break down the steps involved in getting text data ready for analysis. <br>\n",
    "Think of it as cleaning and organizing text so that it's easier to understand and work with. <br>\n",
    "This process helps us get valuable insights when we're dealing with large amounts of text information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics To Be Covered:\n",
    "\n",
    "### Basics:\n",
    "\n",
    "- Lowercasing\n",
    "- HTML Tag Removal\n",
    "- URLs Removal\n",
    "- Punctuation Removal\n",
    "- Chat Word Treatment\n",
    "- Spelling Correction\n",
    "- Stop Word Removal\n",
    "- Handling Emojis\n",
    "- Tokenization\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "\n",
    "### Advance:\n",
    "\n",
    "- Parts Of Speech Tagging\n",
    "- Chunking\n",
    "- Parsing\n",
    "- Co-Reference Resolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB_df = pd.read_csv('Datasets/IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercasing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\n"
     ]
    }
   ],
   "source": [
    "print(IMDB_df['review'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB_df['review'] = IMDB_df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. <br /><br />the...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB_df['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing HTML Tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a wonderful little production. <br /><br />the filming technique is very unassuming- very old-time-bbc fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />the actors are extremely well chosen- michael sheen not only \"has got all the polari\" but he has all the voices down pat too! you can truly see the seamless editing guided by the references to williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. a masterful production about one of the great master's of comedy and his life. <br /><br />the realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. it plays on our knowledge and our senses, particularly with the scenes concerning orton and halliwell and the sets (particularly of their flat with halliwell's murals decorating every surface) are terribly well done.\n"
     ]
    }
   ],
   "source": [
    "print(IMDB_df['review'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove HTML tags from the text\n",
    "\n",
    "def remove_HTML_Tag(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a wonderful little production. the filming technique is very unassuming- very old-time-bbc fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. the actors are extremely well chosen- michael sheen not only \"has got all the polari\" but he has all the voices down pat too! you can truly see the seamless editing guided by the references to williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. a masterful production about one of the great master's of comedy and his life. the realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. it plays on our knowledge and our senses, particularly with the scenes concerning orton and halliwell and the sets (particularly of their flat with halliwell's murals decorating every surface) are terribly well done.\n"
     ]
    }
   ],
   "source": [
    "text = remove_HTML_Tag(IMDB_df['review'][1])\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. the filming tec...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB_df['review'] = IMDB_df['review'].apply(remove_HTML_Tag)\n",
    "\n",
    "IMDB_df['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_url_1 = \"If you're interested in learning more about web development, check out the https://developer.mozilla.org/en-US/. They have comprehensive tutorials and guides for HTML, CSS, and JavaScript.\"\n",
    "text_url_2 = \"For those keen on exploring data science, https://www.kaggle.com/ is a great platform to practice coding, find datasets, and participate in competitions.\"\n",
    "text_url_3 = \"If you want to stay updated on the latest tech trends, http://techcrunch.com/ is an excellent resource for articles and news.\"\n",
    "text_url_4 = \"Finally, if you're looking to enhance your coding skills, I highly recommend https://leetcode.com/ for practicing coding problems.\"\n",
    "text_url_5 = \"All this can be searched on chrome browser with the link www.google.com.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you're interested in learning more about web development, check out the  They have comprehensive tutorials and guides for HTML, CSS, and JavaScript.\n",
      "\n",
      "\n",
      "\n",
      "For those keen on exploring data science,  is a great platform to practice coding, find datasets, and participate in competitions.\n",
      "\n",
      "\n",
      "\n",
      "If you want to stay updated on the latest tech trends,  is an excellent resource for articles and news.\n",
      "\n",
      "\n",
      "\n",
      "Finally, if you're looking to enhance your coding skills, I highly recommend  for practicing coding problems.\n",
      "\n",
      "\n",
      "\n",
      "All this can be searched on chrome browser with the link \n"
     ]
    }
   ],
   "source": [
    "print(remove_url(text_url_1))\n",
    "print('\\n\\n')\n",
    "\n",
    "print(remove_url(text_url_2))\n",
    "print('\\n\\n')\n",
    "\n",
    "print(remove_url(text_url_3))\n",
    "print('\\n\\n')\n",
    "\n",
    "print(remove_url(text_url_4))\n",
    "print('\\n\\n')\n",
    "\n",
    "print(remove_url(text_url_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Punctuations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "# All the punctuation characters recognized by Python\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_punctuation1 = '''\"Wow! He said, 'It costs $5 & it's 50/'%'/ off, so I'll take it (even though 5 < 10 = true)!'\"'''\n",
    "text_punctuation2 = \"In Python, you can use symbols like #, $, %, &, *, +, -, /, :, ;, <, =, >, ?, @, [, , ], ^, _, `, {, |, }, ~ in various contexts.!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation_normal(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow He said It costs 5  its 50 off so Ill take it even though 5  10  true\n",
      "\n",
      "In Python you can use symbols like                          in various contexts\n",
      "Total Time Taken (Normal Method): 63.169002532958984\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Removing punctuation using the normal method\n",
    "print(remove_punctuation_normal(text_punctuation1))\n",
    "print()\n",
    "print(remove_punctuation_normal(text_punctuation2))\n",
    "\n",
    "time1 = time.time() - start\n",
    "\n",
    "# Let's assume that we have 50,000 lines in our document, assuming the above text is one line:\n",
    "print(\"Total Time Taken (Normal Method):\", time1 * 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation_advance(text):\n",
    "    return text.translate(str.maketrans('', '', exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow He said It costs 5  its 50 off so Ill take it even though 5  10  true\n",
      "\n",
      "In Python you can use symbols like                          in various contexts\n",
      "Total Time Taken (Advanced Method): 50.008296966552734\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Removing punctuation using the advanced method\n",
    "print(remove_punctuation_advance(text_punctuation1))\n",
    "print()\n",
    "print(remove_punctuation_advance(text_punctuation2))\n",
    "\n",
    "time2 = time.time() - start\n",
    "\n",
    "# Let's assume that we have 50,000 lines in our document, assuming the above text is one line:\n",
    "print(\"Total Time Taken (Advanced Method):\", time2 * 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Twitter_df = pd.read_csv(\n",
    "    'Datasets/Twitter Hate Speech and Offensive Language Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "1        !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
       "2        !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
       "3        !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
       "4        !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
       "                               ...                        \n",
       "24778    you's a muthaf***in lie &#8220;@LifeAsKing: @2...\n",
       "24779    you've gone and broke the wrong heart baby, an...\n",
       "24780    young buck wanna eat!!.. dat nigguh like I ain...\n",
       "24781                youu got wild bitches tellin you lies\n",
       "24782    ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Twitter_df['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         RT mayasolovely As a woman you shouldnt compl...\n",
       "1         RT mleew17 boy dats coldtyga dwn bad for cuff...\n",
       "2         RT UrKindOfBrand Dawg RT 80sbaby4life You eve...\n",
       "3           RT CGAnderson vivabased she look like a tranny\n",
       "4         RT ShenikaRoberts The shit you hear about me ...\n",
       "                               ...                        \n",
       "24778    yous a muthafin lie 8220LifeAsKing 20Pearls co...\n",
       "24779    youve gone and broke the wrong heart baby and ...\n",
       "24780    young buck wanna eat dat nigguh like I aint fu...\n",
       "24781                youu got wild bitches tellin you lies\n",
       "24782    Ruffled  Ntac Eileen Dahlia  Beautiful color c...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Twitter_df['tweet'] = Twitter_df['tweet'].apply(remove_punctuation_advance)\n",
    "Twitter_df['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Word Treatment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {\n",
    "    'AFAIK': 'As Far As I Know',\n",
    "    'AFK': 'Away From Keyboard',\n",
    "    'ASAP': 'As Soon As Possible',\n",
    "    'ATK': 'At The Keyboard',\n",
    "    'ATM': 'At The Moment',\n",
    "    'A3': 'Anytime, Anywhere, Anyplace',\n",
    "    'BAK': 'Back At Keyboard',\n",
    "    'BBL': 'Be Back Later',\n",
    "    'BBS': 'Be Back Soon',\n",
    "    'BFN': 'Bye For Now',\n",
    "    'B4N': 'Bye For Now',\n",
    "    'BRB': 'Be Right Back',\n",
    "    'BRT': 'Be Right There',\n",
    "    'BTW': 'By The Way',\n",
    "    'B4': 'Before',\n",
    "    'CU': 'See You',\n",
    "    'CUL8R': 'See You Later',\n",
    "    'CYA': 'See You',\n",
    "    'FAQ': 'Frequently Asked Questions',\n",
    "    'FC': 'Fingers Crossed',\n",
    "    'FWIW': 'For What It Is Worth',\n",
    "    'FYI': 'For Your Information',\n",
    "    'GAL': 'Get A Life',\n",
    "    'GG': 'Good Game',\n",
    "    'GN': 'Good Night',\n",
    "    'GMTA': 'Great Minds Think Alike',\n",
    "    'GR8': 'Great!',\n",
    "    'G9': 'Genius',\n",
    "    'IC': 'I See',\n",
    "    'ICQ': 'I Seek You (also a chat program)',\n",
    "    'ILU': 'I Love You',\n",
    "    'IMHO': 'In My Honest/Humble Opinion',\n",
    "    'IMO': 'In My Opinion',\n",
    "    'IOW': 'In Other Words',\n",
    "    'IRL': 'In Real Life',\n",
    "    'KISS': 'Keep It Simple, Stupid',\n",
    "    'LDR': 'Long Distance Relationship',\n",
    "    'LMAO': 'Laugh My A.. Off',\n",
    "    'LOL': 'Laughing Out Loud',\n",
    "    'LTNS': 'Long Time No See',\n",
    "    'L8R': 'Later',\n",
    "    'MTE': 'My Thoughts Exactly',\n",
    "    'M8': 'Mate',\n",
    "    'NRN': 'No Reply Necessary',\n",
    "    'OIC': 'Oh I See',\n",
    "    'PITA': 'Pain In The A..',\n",
    "    'PRT': 'Party',\n",
    "    'PRW': 'Parents Are Watching',\n",
    "    'QPSA?': 'Que Pasa?',\n",
    "    'ROFL': 'Rolling On The Floor Laughing',\n",
    "    'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
    "    'ROTFLMAO': 'Rolling On The Floor Laughing My A.. Off',\n",
    "    'SK8': 'Skate',\n",
    "    'STATS': 'Your sex and age',\n",
    "    'ASL': 'Age, Sex, Location',\n",
    "    'THX': 'Thank You',\n",
    "    'TTFN': 'Ta-Ta For Now!',\n",
    "    'TTYL': 'Talk To You Later',\n",
    "    'U': 'You',\n",
    "    'U2': 'You Too',\n",
    "    'U4E': 'Yours For Ever',\n",
    "    'WB': 'Welcome Back',\n",
    "    'WTF': 'What The F...',\n",
    "    'WTG': 'Way To Go!',\n",
    "    'WUF': 'Where Are You From?',\n",
    "    'W8': 'Wait...',\n",
    "    '7K': 'Sick:-D Laugher',\n",
    "    'TFW': 'That Feeling When',\n",
    "    'MFW': 'My Face When',\n",
    "    'MRW': 'My Reaction When',\n",
    "    'IFYP': 'I Feel Your Pain',\n",
    "    'TNTL': 'Trying Not To Laugh',\n",
    "    'JK': 'Just Kidding',\n",
    "    'IDC': 'I Don’t Care',\n",
    "    'ILY': 'I Love You',\n",
    "    'IMU': 'I Miss You',\n",
    "    'ADIH': 'Another Day In Hell',\n",
    "    'ZZZ': 'Sleeping, Bored, Tired',\n",
    "    'WYWH': 'Wish You Were Here',\n",
    "    'TIME': 'Tears In My Eyes',\n",
    "    'BAE': 'Before Anyone Else',\n",
    "    'FIMH': 'Forever In My Heart',\n",
    "    'BSAAW': 'Big Smile And A Wink',\n",
    "    'BWL': 'Bursting With Laughter',\n",
    "    'BFF': 'Best Friends Forever',\n",
    "    'CSL': 'Can’t Stop Laughing'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_text = \"LOL, that was so funny! BRB, need to grab something. BTW, TTYL!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversation(text):\n",
    "    new_text = []\n",
    "\n",
    "    for w in text.split():\n",
    "        # Strip punctuation from the word to check it against the dictionary\n",
    "        word = w.strip(string.punctuation)\n",
    "\n",
    "        if word.upper() in chat_words:\n",
    "            # Append the expanded form and keep the original punctuation\n",
    "            new_text.append(chat_words[word.upper()] + w[len(word):])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "\n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laughing Out Loud, that was so funny! Be Right Back, need to grab something. By The Way, Talk To You Later!\n"
     ]
    }
   ],
   "source": [
    "print(chat_conversation(chat_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling Correction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_spellings = \"The qwik bron fox jumpt ovr the lazi dogg, wile teh brids singging in teh tress.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quick iron fox jump or the lazy dog, will the birds singing in the dress.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textBlb = TextBlob(incorrect_spellings)\n",
    "\n",
    "textBlb.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stop Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_sentence = \"I just wanted to tell you that if we go to the store, we can get some of the things that we need, but only if you think it’s a good idea, and then maybe after that, we can go to the park where we can sit and relax for a while, because I think it would be nice to spend some time together just talking about what’s been going on lately.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    new_text = []\n",
    "\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return ' '.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I  wanted  tell     go   store,   get    things   need,     think it’s  good idea,   maybe  that,   go   park    sit  relax   while,  I think  would  nice  spend  time together  talking  what’s  going  lately.\n"
     ]
    }
   ],
   "source": [
    "print(remove_stop_words(stop_words_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Emojis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to handle Emojis in our data:\n",
    "\n",
    "1. Either we can replace them with their meaning or\n",
    "2. We can remove them from our data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Emojis From Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_emojis1 = \"Hello 😊 World! 🌍\"       # Regular emojis\n",
    "text_emojis2 = \"No emojis here!\"     # No emojis\n",
    "text_emojis3 = \"Emojis like 🚀 and 🌟 are fun!\"     # Mixemojis and flags\n",
    "text_emojis4 = \"Complex 😜 string with emojis 😁 and flags 🇺🇸\"\n",
    "text_emojis5 = \"\"       # Empty string\n",
    "text_emojis6 = \"🤖🤖🤖\"     # Only emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(text):\n",
    "    # Define a pattern for emojis using Unicode ranges\n",
    "    emojis_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"    # Emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"    # Symbols and Pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"    # Transport and Map Symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"    # Flags (iOS)\n",
    "        u\"\\U000024C2-\\U0001F251\"    # Enclosed characters and other symbols\n",
    "        \"]\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emojis_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello  World! \n",
      "No emojis here!\n",
      "Emojis like  and  are fun!\n",
      "Complex  string with emojis  and flags \n",
      "\n",
      "🤖🤖🤖\n"
     ]
    }
   ],
   "source": [
    "print(remove_emojis(text_emojis1))\n",
    "print(remove_emojis(text_emojis2))\n",
    "print(remove_emojis(text_emojis3))\n",
    "print(remove_emojis(text_emojis4))\n",
    "print(remove_emojis(text_emojis5))\n",
    "print(remove_emojis(text_emojis6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing Emojis with their meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is :fire:\n",
      ":face_blowing_a_kiss: the :hot_beverage: that :index_pointing_at_the_viewer: made yesterday\n"
     ]
    }
   ],
   "source": [
    "print(emoji.demojize('Python is 🔥'))\n",
    "print(emoji.demojize('😘 the ☕ that 🫵 made yesterday'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
